// Uses Nq x Nq threads

// (grad v, grad q) + ([v], n.{grad q}) + (n.{grad v}, [q]) + ([v],tau*[q])
// (grad v, grad q) + (-v, n.{grad q}) + (n.grad v-, (q+ - q-)) + (-v,tau*(q+-q-))
// (grad v, grad q + delta*n*(q+-q-)) + (-v, n.{grad q} + tau*(q+-q-))
// (G*grad^ v, G*grad^ q + delta*n*(q+-q-)) + (-v, n.{grad q} + tau*(q+-q-))
// (grad^ v, G'*G*grad^ q + delta*(G'*n)*(q+ - q-)) + (-v, n.{grad q} + tau*(q+-q-))

// independent faces: (0,5), (1,3), (2,4)

//  (2,4), (3,9), (4,16), 

void computeGeofacs(const dfloat r, const dfloat s, const dfloat t,
		    const dfloat *VXYZ,
		    dfloat *G00, dfloat *G01, dfloat *G02,
		    dfloat *G11, dfloat *G12, dfloat *G22){
  
  // assume trilinear map
  const dfloat x0 = VXYZ[0],  y0 = VXYZ[1],  z0 = VXYZ[2];
  const dfloat x1 = VXYZ[3],  y1 = VXYZ[4],  z1 = VXYZ[5];
  const dfloat x2 = VXYZ[6],  y2 = VXYZ[7],  z2 = VXYZ[8];
  const dfloat x3 = VXYZ[9],  y3 = VXYZ[10], z3 = VXYZ[11];
  const dfloat x4 = VXYZ[12], y4 = VXYZ[13], z4 = VXYZ[14];
  const dfloat x5 = VXYZ[15], y5 = VXYZ[16], z5 = VXYZ[17];
  const dfloat x6 = VXYZ[18], y6 = VXYZ[19], z6 = VXYZ[20];
  const dfloat x7 = VXYZ[21], y7 = VXYZ[22], z7 = VXYZ[23];

  const dfloat xr =
    (1.f-s)*(1.f-t)*(x1-x0) +
    (1.f+s)*(1.f-t)*(x2-x3) +
    (1.f-s)*(1.f+t)*(x5-x4) +
    (1.f+s)*(1.f+t)*(x6-x7);

  const dfloat xs =
    (1.f-r)*(1.f-t)*(x3-x0) +
    (1.f+r)*(1.f-t)*(x2-x1) +
    (1.f-r)*(1.f+t)*(x7-x4) +
    (1.f+r)*(1.f+t)*(x6-x5);


  const dfloat xt =
    (1.f-r)*(1.f-s)*(x4-x0) +
    (1.f+r)*(1.f-s)*(x5-x1) +
    (1.f-r)*(1.f+s)*(x7-x3) +
    (1.f+r)*(1.f+s)*(x6-x2);

  const dfloat yr =
    (1.f-s)*(1.f-t)*(y1-y0) +
    (1.f+s)*(1.f-t)*(y2-y3) +
    (1.f-s)*(1.f+t)*(y5-y4) +
    (1.f+s)*(1.f+t)*(y6-y7);

  const dfloat ys =
    (1.f-r)*(1.f-t)*(y3-y0) +
    (1.f+r)*(1.f-t)*(y2-y1) +
    (1.f-r)*(1.f+t)*(y7-y4) +
    (1.f+r)*(1.f+t)*(y6-y5);


  const dfloat yt =
    (1.f-r)*(1.f-s)*(y4-y0) +
    (1.f+r)*(1.f-s)*(y5-y1) +
    (1.f-r)*(1.f+s)*(y7-y3) +
    (1.f+r)*(1.f+s)*(y6-y2);


  const dfloat zr =
    (1.f-s)*(1.f-t)*(z1-z0) +
    (1.f+s)*(1.f-t)*(z2-z3) +
    (1.f-s)*(1.f+t)*(z5-z4) +
    (1.f+s)*(1.f+t)*(z6-z7);

  const dfloat zs =
    (1.f-r)*(1.f-t)*(z3-z0) +
    (1.f+r)*(1.f-t)*(z2-z1) +
    (1.f-r)*(1.f+t)*(z7-z4) +
    (1.f+r)*(1.f+t)*(z6-z5);


  const dfloat zt =
    (1.f-r)*(1.f-s)*(z4-z0) +
    (1.f+r)*(1.f-s)*(z5-z1) +
    (1.f-r)*(1.f+s)*(z7-z3) +
    (1.f+r)*(1.f+s)*(z6-z2);

  const dfloat J = xr*(ys*zt-zs*yt) - yr*(xs*zt-zs*xt) + zr*(xs*yt-ys*xt);
  const dfloat Jinv = 8.f/J;
  const dfloat rx =  (ys*zt - zs*yt)*Jinv, ry = -(xs*zt - zs*xt)*Jinv, rz =  (xs*yt - ys*xt)*Jinv;
  const dfloat sx = -(yr*zt - zr*yt)*Jinv, sy =  (xr*zt - zr*xt)*Jinv, sz = -(xr*yt - yr*xt)*Jinv;
  const dfloat tx =  (yr*zs - zr*ys)*Jinv, ty = -(xr*zs - zr*xs)*Jinv, tz =  (xr*ys - yr*xs)*Jinv;

  *G00 = rx*rx + ry*ry + rz*rz;
  *G01 = rx*sx + ry*sy + rz*sz;
  *G02 = rx*tx + ry*ty + rz*tz;
  *G11 = sx*sx + sy*sy + sz*sz;
  *G12 = sx*tx + sy*ty + sz*tz;
  *G22 = tx*tx + ty*ty + tz*tz;
  

}

kernel void ScalarEllipticSlicedOperator3D(const int K,
					   const dfloat * restrict D, 
					   const dfloat * restrict gz,
					   const dfloat * restrict VXYZ,
					   const dfloat * restrict sgeo,
					   const dfloat * restrict q,
					   const dfloat * restrict qP,
					   const dfloat * restrict dqdnM,
					   const dfloat * restrict dqdnP,
					   dfloat * restrict Aq){
  

  // can split into outer0/inner1
  for(int eo=0;eo<K;eo+=p_Kblk;outer0){

    // 4*p_Nq^2 shared dfloats (N=4 => 400 bytes)
    // need to tune pading

#if p_Nq == 4 || p_Nq == 8
#define p_PAD 1
#else
#define p_PAD 0
#endif
    
    volatile shared dfloat s_D[p_Nq][p_Nq+p_PAD];
    volatile shared dfloat s_q[p_Kblk][p_Nq][p_Nq+p_PAD];
    volatile shared dfloat s_Dq0[p_Kblk][p_Nq][p_Nq+p_PAD];
    volatile shared dfloat s_Dq1[p_Kblk][p_Nq][p_Nq+p_PAD];
    
    volatile shared dfloat s_qP[p_Kblk][p_Nfaces][p_Nq][p_Nq];
    volatile shared dfloat s_avedqdn[p_Kblk][p_Nfaces][p_Nq][p_Nq];

    shared dfloat s_VXYZ[p_Kblk][8*3];
    
    // 2*p_Nq + 3 exclusive floats (N=4 => 14 registers blocked)
    exclusive dfloat r_q[p_Nq];
    exclusive dfloat r_Aq[p_Nq];
    exclusive dfloat r_dq05, r_dq13, r_dq24; // save jump in q
    
    // prefetch to registers and shared memory
    for(int ei=0;ei<p_Kblk;++ei;inner2){
      for(int j=0;j<p_Nq;++j;inner1){
	for(int i=0;i<p_Nq;++i;inner0){
	  const int e = ei + eo;

	  for(int k=0;k<p_Nq;++k){ 
	    const int id = i + j*p_Nq + k*p_Nq2 + e*p_Nq3;
	    r_q[k] = q[id];
	    r_Aq[k] = 0.f;
	  }

	  // this line causes parser fail
	  if(ei==0){ // 
	    s_D[j][i] = D[j*p_Nq+i];
	  }  

	  // may wish to restore full load
	  for(int f=0;f<p_Nfaces;++f){
	    const int idM = i + j*p_Nq + f*p_Nq2 + e*p_Nfaces*p_Nq2;
	    s_qP[ei][f][j][i] = qP[idM];
	    s_avedqdn[ei][f][j][i] = dqdnP[idM] + dqdnM[idM];
	  }

	  int id = i + j*p_Nq;
	  while(id<24){
	    s_VXYZ[ei][id] = VXYZ[e*24+id];
	    id+=p_Nq*p_Nq;
	  }
	}
      }
    }

    // compute first derivatives
    // #pragma unroll
    occaUnroll(p_Nq)
    for(int k=0;k<p_Nq;++k){

      // do not need a barrier here - since there is a barrier either side of s_q access
      barrier(localMemFence);
      
      // copy to shared
      for(int ei=0;ei<p_Kblk;++ei;inner2){
	for(int j=0;j<p_Nq;++j;inner1){
	  for(int i=0;i<p_Nq;++i;inner0){
	    s_q[ei][j][i] = r_q[k];
	  }
	}
      }
	
      barrier(localMemFence);

      for(int ei=0;ei<p_Kblk;++ei;inner2){
	for(int j=0;j<p_Nq;++j;inner1){
	  for(int i=0;i<p_Nq;++i;inner0){
	    const int e = ei + eo;

	    dfloat G00, G01, G02, G11 ,G12, G22;
	    // VXYZ + 8*3*e,
	    computeGeofacs(gz[i], gz[j], gz[k], s_VXYZ[ei],
			   &G00, &G01, &G02, &G11, &G12, &G22);
	    
	    dfloat qr = 0.f, qs = 0.f, qt = 0.f;
	      
	    // flops = 6*Nq*Nq*Nq*Nq
	    occaUnroll(p_Nq)
	      for(int n=0;n<p_Nq;++n){
		qr += s_D[i][n]*s_q[ei][j][n];
		qs += s_D[j][n]*s_q[ei][n][i];
		qt += s_D[k][n]*r_q[n];
	      }
	  
	      
	    // flops = 15*Nq*Nq*Nq
	    dfloat r_Dq0 = G00*qr + G01*qs + G02*qt;
	    dfloat r_Dq1 = G01*qr + G11*qs + G12*qt;
	    dfloat r_Dq2 = G02*qr + G12*qs + G22*qt;
	      
	    // flops = 6*7*Nq*Nq
	    // add terms at face nodes to contribute to (grad v, [q]) terms
	    // faces: (0:5)
	    if(k==0 || k==p_Nq-1){
	      const int f = (k==0)?0:5;
	      int idG = p_Nsgeo*e*p_Nq2*p_Nfaces + p_Nsgeo*f*p_Nq2 + j*p_Nq + i;

	      // could read qP directly here
	      //	      int idM = e*p_Nq2*p_Nfaces + f*p_Nq2 + j*p_Nq + i;
	      //r_dq05 = qP[idM]-r_q[k];

	      // compute trace jump
	      r_dq05 = s_qP[ei][f][j][i]-r_q[k];

	      
	      // assume sgeo contains G'*n
	      r_Dq0 += sgeo[idG]*r_dq05; idG+=p_Nq2;
	      r_Dq1 += sgeo[idG]*r_dq05; idG+=p_Nq2;
	      r_Dq2 += sgeo[idG]*r_dq05; 
	    }
	      
	    // faces: (1,3)
	    if(j==0 || j==p_Nq-1){ 
	      const int f = (j==0) ? 1:3;
	      int idG = p_Nsgeo*e*p_Nq2*p_Nfaces + p_Nsgeo*f*p_Nq2 + k*p_Nq + i;
		
	      // compute trace jump
	      r_dq13 = s_qP[ei][f-1][k][i]-r_q[k];
		
	      // assume sgeo contains G'*n
	      r_Dq0 += sgeo[idG]*r_dq13; idG+=p_Nq2;
	      r_Dq1 += sgeo[idG]*r_dq13; idG+=p_Nq2;
	      r_Dq2 += sgeo[idG]*r_dq13;
	    }
	      
	    // faces: (2,4)
	    if(i==0 || i==p_Nq-1){ 
	      const int f = (i==0) ? 4:2;
	      int idG = p_Nsgeo*e*p_Nq2*p_Nfaces + p_Nsgeo*f*p_Nq2 + k*p_Nq + j; 
		
	      // compute trace jump
	      r_dq24 = s_qP[ei][f-1][k][j]-r_q[k];
		
	      // assume sgeo contains G'*n
	      r_Dq0 += sgeo[idG]*r_dq24; idG+=p_Nq2;
	      r_Dq1 += sgeo[idG]*r_dq24; idG+=p_Nq2;
	      r_Dq2 += sgeo[idG]*r_dq24;
	    }    
	      
	    s_Dq0[ei][j][i] = r_Dq0;
	    s_Dq1[ei][j][i] = r_Dq1;
	      
	    // flops = 2*Nq*Nq*Nq*Nq
	    // do this here to hide latency of smem write ?
	    //#pragma unroll
	    occaUnroll(p_Nq)
	      for(int n=0;n<p_Nq;++n){
		r_Aq[n] += s_D[k][n]*r_Dq2; // spread over Aq pencil
	      }
	  }
	}
      }
	  
      barrier(localMemFence);
	  
      // compute second (weak) derivatives
      for(int ei=0;ei<p_Kblk;++ei;inner2){
	for(int j=0;j<p_Nq;++j;inner1){
	  for(int i=0;i<p_Nq;++i;inner0){

	    const int e = ei + eo;
	    
	    dfloat Aq0 = 0.f, Aq1 = 0.f;
		
	    // flops = 4*Nq*Nq*Nq*Nq
	    occaUnroll(p_Nq)
	      for(int n=0;n<p_Nq;++n){
		// ILP ?
		Aq0 += s_D[n][i]*s_Dq0[ei][j][n];
		Aq1 += s_D[n][j]*s_Dq1[ei][n][i];
	      }
		
	    // flops = 2*Nq*Nq*Nq
	    r_Aq[k] += Aq0 + Aq1;
	    
	    // flops = 6*4*5*Nq*Nq
	    // could do this part before barrier
	    // add (v, {dq/dn}) + (-v, tau*[q]) terms
	    // faces: (0,5) (not divergent)
	    if(k==0 || k==p_Nq-1){
	      int f = (k==0)?0:5;
	      const int idG = p_Nsgeo*e*p_Nq2*p_Nfaces + p_Nsgeo*f*p_Nq2 + j*p_Nq + i; 
	    
	      r_Aq[k] += -sgeo[idG+ p_idsJ*p_Nq2]*s_avedqdn[ei][f][j][i];
	      r_Aq[k] +=  sgeo[idG+p_idtau*p_Nq2]*r_dq05; // note dq0 is exclusive
	    }
    
	    // faces: (1,3) warp divergence
	    if(j==0 || j==p_Nq-1){
	      int f = (j==0)?1:3;
	      const int idG = p_Nsgeo*e*p_Nq2*p_Nfaces + p_Nsgeo*f*p_Nq2 + k*p_Nq + i;
	    
	      // could prefetch traces
	      r_Aq[k] += -sgeo[idG+ p_idsJ*p_Nq2]*s_avedqdn[ei][f][k][i];
	      r_Aq[k] +=  sgeo[idG+p_idtau*p_Nq2]*r_dq13;
	    }

	    // faces: (2,4) (warp divergence)
	    if(i==0 || i==p_Nq-1){ 
	      int f = (i==0)?4:2;
	      const int idG = p_Nsgeo*e*p_Nq2*p_Nfaces + p_Nsgeo*f*p_Nq2 + k*p_Nq + j;

	      // check signs
	      r_Aq[k] += -sgeo[idG+ p_idsJ*p_Nq2]*s_avedqdn[ei][f][k][j];
	      r_Aq[k] +=  sgeo[idG+p_idtau*p_Nq2]*r_dq24;
	    }    
	  }
	}
      }

      barrier(localMemFence);
      
      // need this k-loop to be separate since r_Aq is built progressively
      for(int ei=0;ei<p_Kblk;++ei;inner2){
	for(int j=0;j<p_Nq;++j;inner1){
	  for(int i=0;i<p_Nq;++i;inner0){
	    const int e = ei + eo;
	    occaUnroll(p_Nq)
	    for(int k=0;k<p_Nq;++k){	    
	      const int id = i + j*p_Nq + k*p_Nq2 + e*p_Nq3;
	      Aq[id] = r_Aq[k];
	    }
	  }
	}
      }
    }
  }
}
